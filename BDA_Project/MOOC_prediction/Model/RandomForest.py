import pandas as pd
import numpy as np
import os
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix

# --------------------- ì „ì—­ ì„¤ì • ---------------------
TEST_SIZE = 0.2           # ê²€ì¦ ë¹„ìœ¨
RANDOM_SEED = 42          # ì¬í˜„ì„±
USE_TUNING = True         # í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì—¬ë¶€ (True/False)

# ----------------- 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° -----------------
df = pd.read_csv("C:/Users/ilumi/BDA_Project/data/train.csv")

# -------------- 2. íƒ€ê¹ƒ ë¶„ë¦¬ & ì—´ ì‚­ì œ ----------------
y = df["withdrawal"].copy()
drop_cols = ["ID", "generation", "class4", "withdrawal"]
df.drop(columns=[c for c in drop_cols if c in df.columns], inplace=True)

# --------- 3. ê²°ì¸¡ë¥  90% ì´ìƒ ì—´ ì œê±° ------------------
high_null_cols = df.columns[df.isnull().mean() >= 0.9]
df.drop(columns=high_null_cols, inplace=True)

# --------------- 4. ê²°ì¸¡ì¹˜ â€œë¬´ì‘ë‹µâ€ ë³´ê°„ ---------------
df.fillna("ë¬´ì‘ë‹µ", inplace=True)

# --------- 5. ëª¨ë“  ì»¬ëŸ¼ category â†’ code ì¸ì½”ë”© ----------
for col in df.columns:
    df[col] = df[col].astype("category").cat.codes

y = y.astype("category").cat.codes  # íƒ€ê¹ƒ ì¸ì½”ë”©

# ------------- 6. í•™ìŠµ/ê²€ì¦ ë°ì´í„° ë¶„í•  ---------------
X_train, X_test, y_train, y_test = train_test_split(
    df, y, test_size=TEST_SIZE, random_state=RANDOM_SEED, stratify=y
)

# ------------- 7. RandomForest ëª¨ë¸ ì •ì˜ ----------------
base_rf = RandomForestClassifier(
    random_state=RANDOM_SEED,
    class_weight="balanced",
    n_jobs=-1
)

# --------- 8. í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (GridSearchCV) --------
if USE_TUNING:
    param_grid = {
        "n_estimators": [100, 300, 500],
        "max_depth": [5, 10, 15],
        "min_samples_leaf": [1, 3, 5],
        "max_features": ["sqrt"]
    }

    grid_search = GridSearchCV(
        estimator=base_rf,
        param_grid=param_grid,
        cv=3,
        scoring="f1",  # ì´ì§„ ë¶„ë¥˜ì—ì„œ F1 ì‚¬ìš©
        verbose=1,
        n_jobs=-1
    )
    grid_search.fit(X_train, y_train)
    rf = grid_search.best_estimator_
    print("ğŸ¯ Best Params:", grid_search.best_params_)
else:
    rf = RandomForestClassifier(
        n_estimators=300,
        max_depth=None,
        random_state=RANDOM_SEED,
        class_weight="balanced",
        n_jobs=-1
    )
    rf.fit(X_train, y_train)

# ------------- 9. ì„±ëŠ¥ í‰ê°€ ---------------------------
y_pred = rf.predict(X_test)

print("\nğŸ“‹ Classification Report:")
print(classification_report(y_test, y_pred, digits=4))

# ------------- 10. Confusion Matrix & Heatmap ----------
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=["0 (X)", "1 (O)"], yticklabels=["0 (X)", "1 (O)"])
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix Heatmap")
plt.tight_layout()
plt.show()

# ------------- 11. Feature Importance ------------------
importances = rf.feature_importances_
feat_names  = df.columns
indices     = np.argsort(importances)[::-1]

plt.figure(figsize=(14, 6))
plt.title("RandomForest Feature Importances (Top 20)")
plt.bar(range(20), importances[indices][:20], align="center")
plt.xticks(range(20), [feat_names[i] for i in indices[:20]], rotation=90)
plt.tight_layout()
plt.show()

# ------------- 12. í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸ --------------------
print("\nâœ… ì „ì²´ í´ë˜ìŠ¤ ë¶„í¬:")
print(y.value_counts(normalize=True))

print("\nâœ… í›ˆë ¨ì…‹ í´ë˜ìŠ¤ ë¶„í¬:")
print(y_train.value_counts(normalize=True))

print("\nâœ… ê²€ì¦ì…‹ í´ë˜ìŠ¤ ë¶„í¬:")
print(y_test.value_counts(normalize=True))



# ----------------- 13. test.csv ì˜ˆì¸¡ ------------------
# ê²½ë¡œ ì„¤ì •
TEST_PATH = "C:/Users/ilumi/BDA_Project/data/test.csv"
SUBMIT_PATH = "C:/Users/ilumi/BDA_Project/data/sample_submission.csv"
SAVE_PATH = "C:/Users/ilumi/BDA_Project/data/final_submission.csv"

# test.csv ë¡œë”©
test_df = pd.read_csv(TEST_PATH)
test_id = test_df["ID"].copy()  # ë‚˜ì¤‘ì— ì œì¶œìš© ID

# ì „ì²˜ë¦¬ (trainê³¼ ë™ì¼í•˜ê²Œ)
test_df.drop(columns=["ID", "generation", "class4"], inplace=True)

# í›ˆë ¨ ë°ì´í„° ê¸°ì¤€ ê²°ì¸¡ë¥  90% ì´ìƒ ì»¬ëŸ¼ ì œê±°
test_df.drop(columns=[col for col in high_null_cols if col in test_df.columns], inplace=True)

# ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ë° ì¸ì½”ë”©
test_df.fillna("ë¬´ì‘ë‹µ", inplace=True)
for col in test_df.columns:
    test_df[col] = test_df[col].astype("category").cat.codes

# ì˜ˆì¸¡
test_preds = rf.predict(test_df)

# ----------------- 14. ì œì¶œ íŒŒì¼ ì €ì¥ ------------------
submission = pd.read_csv(SUBMIT_PATH)
submission["withdrawal"] = test_preds
submission.to_csv(SAVE_PATH, index=False)

print(f"\nğŸ“ ì œì¶œ íŒŒì¼ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {SAVE_PATH}")